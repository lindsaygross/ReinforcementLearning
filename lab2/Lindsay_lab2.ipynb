{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "Run on colab: <a href=\"https://colab.research.google.com/github/lindsaygross/ReinforcementLearning/blob/main/Lindsay_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_lHlqACuufS"
      },
      "source": [
        "# Lab 2\n",
        "### Tabular RL on FrozenLake: Planning vs Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2_Fn9bnu2hK"
      },
      "source": [
        "#### Learning Goals\n",
        "\n",
        "By the end of this lab, you should be able to:\n",
        "\n",
        "* Describe an RL problem as an MDP: ⟨S, A, P, R, γ⟩\n",
        "\n",
        "* Compute an optimal value function using Value Iteration (planning; model-based)\n",
        "\n",
        "* Learn an optimal action-value function using Q-learning (learning; model-free)\n",
        "\n",
        "* Explain how both use the same core idea: Bellman optimality backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "znG2eFUSu0B2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lindsaygross/ME AIPI Code/RL/ReinforcementLearning/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%pip install -q gymnasium\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOVMVV7dvK_i"
      },
      "source": [
        "### Setting up a reproducible environment\n",
        "\n",
        "FrozenLake is a finite MDP, which makes it ideal for studying tabular methods.\n",
        "\n",
        "We set:\n",
        "\n",
        "`is_slippery=False` so transitions are deterministic\n",
        "* this isolates Bellman updates from stochastic noise\n",
        "* we will turn stochasticity back on later\n",
        "\n",
        "\n",
        "\n",
        "This environment gives us:\n",
        "\n",
        "A finite state space (S)\n",
        "\n",
        "A finite action space (A)\n",
        "\n",
        "A well-defined transition model P(s′ | s, a)\n",
        "\n",
        "A reward function R(s, a, s′)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm_skRyPuq7f",
        "outputId": "bb1be686-aae9-4680-de96-1c19e144a7b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nS (states) = 16\n",
            "nA (actions) = 4\n"
          ]
        }
      ],
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Deterministic dynamics. We'll flip is_slippery=True later!\n",
        "env = gym.make(\"FrozenLake-v1\", map_name=\"4x4\", is_slippery=False, render_mode=\"rgb_array\")\n",
        "\n",
        "_ = env.reset(seed=SEED)\n",
        "env.action_space.seed(SEED)\n",
        "env.observation_space.seed(SEED)\n",
        "\n",
        "nS = env.observation_space.n\n",
        "nA = env.action_space.n\n",
        "\n",
        "print(\"nS (states) =\", nS)\n",
        "print(\"nA (actions) =\", nA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_iHnsUFvPgE"
      },
      "source": [
        "### The MDP\n",
        "\n",
        "FrozenLake is a finite MDP:\n",
        "\n",
        "**States:** S = {0, 1, …, 15} (each tile in the 4×4 grid)\n",
        "\n",
        "**Actions:** A = {0, 1, 2, 3} (LEFT, DOWN, RIGHT, UP)\n",
        "\n",
        "**Transitions:** P(s′ | s, a)\n",
        "\n",
        "**Reward:** typically 1 when you reach the goal, else 0\n",
        "\n",
        "**Discount:** γ ∈ [0, 1)\n",
        "\n",
        "We are going to extract the environment’s transition model **P** and inspect it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tIHzYoJvHEh",
        "outputId": "5600bd35-aea8-4fb3-8299-49b14d5da90e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys in P (states): [0, 1, 2, 3, 4] ...\n",
            "Example transitions P[0][0]: [(1.0, 0, 0, False)]\n"
          ]
        }
      ],
      "source": [
        "# In FrozenLake, env.unwrapped.P is a dict-like structure: P[s][a] = list of (prob, next_state, reward, terminated)\n",
        "P = env.unwrapped.P\n",
        "\n",
        "# sanity checks\n",
        "print(\"Keys in P (states):\", list(P.keys())[:5], \"...\")\n",
        "print(\"Example transitions P[0][0]:\", P[0][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnqkOiS4vy2U"
      },
      "source": [
        "### Checkpoint\n",
        "\n",
        "\n",
        "> 1. What does each tuple (prob, next_state, reward, terminated) mean?\n",
        "\n",
        "**Answer:** Each tuple represents a possible transition outcome when taking an action from a state:\n",
        "- `prob`: The probability of this transition occurring (in deterministic environments = 1.0, in stochastic environments can be < 1.0)\n",
        "- `next_state`: The state you land in after taking the action\n",
        "- `reward`: The immediate reward received from this transition\n",
        "- `terminated`: Boolean indicating whether this transition leads to a terminal state (episode ends)\n",
        "\n",
        "> 2. Why is Value Iteration possible here, but not always in real-world RL?\n",
        "\n",
        "**Answer:** Value Iteration requires access to the full transition model P(s'|s,a) and reward function R(s,a,s'). In FrozenLake, we have this model through `env.unwrapped.P`. In most real-world RL problems, we don't have access to this model - we can only observe what happens when we take actions. This is why model-free methods like Q-learning are more widely applicable, as they learn directly from experience without needing the transition dynamics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmjRkslPvinS",
        "outputId": "b1406395-e206-41b7-aafa-6442eeb7e8cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State 0\n",
            "  Action LEFT:\n",
            "    → (p=1.00, s'=0, r=0.0, done=False)\n",
            "  Action DOWN:\n",
            "    → (p=1.00, s'=4, r=0.0, done=False)\n",
            "  Action RIGHT:\n",
            "    → (p=1.00, s'=1, r=0.0, done=False)\n",
            "  Action UP:\n",
            "    → (p=1.00, s'=0, r=0.0, done=False)\n"
          ]
        }
      ],
      "source": [
        "def pretty_print_transitions(P, s, action_names=None):\n",
        "    \"\"\"\n",
        "    Print the transition dynamics for each action at state s.\n",
        "\n",
        "    P[s][a] is a list of tuples:\n",
        "      (probability, next_state, reward, terminated)\n",
        "    \"\"\"\n",
        "    if action_names is None:\n",
        "        action_names = {0: \"LEFT\", 1: \"DOWN\", 2: \"RIGHT\", 3: \"UP\"}\n",
        "\n",
        "    print(f\"State {s}\")\n",
        "    for a in P[s]:\n",
        "        action_label = action_names.get(a, f\"ACTION {a}\")\n",
        "        print(f\"  Action {action_label}:\")\n",
        "        for (p, s_next, r, done) in P[s][a]:\n",
        "            print(f\"    → (p={p:.2f}, s'={s_next}, r={r:.1f}, done={done})\")\n",
        "\n",
        "pretty_print_transitions(P, s=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEn_MhQLwqay"
      },
      "source": [
        "### Value Functions and Bellman Optimality\n",
        "\n",
        "We’ll use two value functions:\n",
        "\n",
        "State-value under a policy π:\n",
        "Vπ(s) = E[ Σₜ γᵗ rₜ | s₀ = s, π ]\n",
        "\n",
        "Optimal value:\n",
        "V*(s) = maxπ Vπ(s)\n",
        "\n",
        "Bellman optimality equation for V*:\n",
        "\n",
        "V*(s) = maxₐ Σₛ′ P(s′|s,a) [ R(s,a,s′) + γ V*(s′) ]\n",
        "\n",
        "*Value Iteration repeatedly applies this “backup” until values stop changing*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDVQ5EVD0y6z"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This function implements one Bellman backup for a single state s\n",
        "\n",
        "Given:\n",
        "\n",
        "Current value estimates V\n",
        "\n",
        "Transition model P\n",
        "\n",
        "Discount factor γ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0Eqcuey2wd3N"
      },
      "outputs": [],
      "source": [
        "def bellman_optimality_backup(P, V, s, gamma):\n",
        "    \"\"\"\n",
        "    Compute:\n",
        "      max_a Σ_s' P(s'|s,a) [ r + γ V(s') ]\n",
        "    TODO: implement this function.\n",
        "\n",
        "    Inputs:\n",
        "      P: transition model\n",
        "      V: np.array shape [nS]\n",
        "      s: int state\n",
        "      gamma: float\n",
        "\n",
        "    Returns:\n",
        "      v_new: float\n",
        "    \"\"\"\n",
        "    # For each action a:\n",
        "    #   compute expected return = Σ over transitions (p * (r + gamma*V[s']))\n",
        "    # return the max over a\n",
        "    action_values = []\n",
        "    for a in P[s]:\n",
        "        expected_return = 0.0\n",
        "        for (prob, next_state, reward, terminated) in P[s][a]:\n",
        "            expected_return += prob * (reward + gamma * V[next_state])\n",
        "        action_values.append(expected_return)\n",
        "    v_new = max(action_values)\n",
        "    return v_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2FVIAyK0-gz"
      },
      "source": [
        "This function repeatedly applies Bellman backups to all states:\n",
        "\n",
        "Initialize V(s) arbitrarily (zeros)\n",
        "\n",
        "For each state:\n",
        "\n",
        "Update V(s) using the Bellman optimality equation\n",
        "\n",
        "Stop when values stop changing (convergence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-19eya2yT9V",
        "outputId": "cfb445ae-c8c8-44ca-f6f9-92b7e71ff027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value Iteration converged in 7 iterations (delta=0.00e+00).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.77378094, 0.81450625, 0.857375  , 0.81450625, 0.81450625,\n",
              "       0.        , 0.9025    , 0.        , 0.857375  , 0.9025    ])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def value_iteration(P, nS, nA, gamma=0.95, theta=1e-8, max_iters=10_000):\n",
        "    \"\"\"\n",
        "    Classic Value Iteration for V*.\n",
        "\n",
        "    TODO:\n",
        "      - implement the update for each state using bellman_optimality_backup\n",
        "      - stop when max change < theta\n",
        "\n",
        "    Returns:\n",
        "      V: optimal state-value np.array shape [nS]\n",
        "    \"\"\"\n",
        "    V = np.zeros(nS, dtype=np.float64)\n",
        "\n",
        "    for it in range(max_iters):\n",
        "        delta = 0.0\n",
        "\n",
        "        # loop over states s\n",
        "        for s in range(nS):\n",
        "            v_old = V[s]\n",
        "            V[s] = bellman_optimality_backup(P, V, s, gamma)\n",
        "            delta = max(delta, abs(v_old - V[s]))\n",
        "\n",
        "        if delta < theta:\n",
        "            print(f\"Value Iteration converged in {it+1} iterations (delta={delta:.2e}).\")\n",
        "            break\n",
        "\n",
        "    return V\n",
        "\n",
        "gamma = 0.95\n",
        "V_star = value_iteration(P, nS, nA, gamma=gamma)\n",
        "V_star[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1uUHK_u1Oq1"
      },
      "source": [
        "Once we have V*(s), we compute:\n",
        "\n",
        "π*(s) = argmaxₐ Σₛ′ P(s′|s,a) [ r + γ V*(s′) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wqEWX32yYLp",
        "outputId": "479d8d24-124b-4898-aa9e-88632b8c111f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 1, 0, 1, 0, 1, 0, 2, 1, 1, 0, 0, 2, 2, 0])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def greedy_policy_from_V(P, V, nS, nA, gamma=0.95):\n",
        "    \"\"\"\n",
        "    π(s) = argmax_a Σ_s' P(s'|s,a) [ r + γ V(s') ]\n",
        "    TODO: implement.\n",
        "\n",
        "    Returns:\n",
        "      pi: np.array shape [nS] containing action index per state\n",
        "    \"\"\"\n",
        "    pi = np.zeros(nS, dtype=np.int64)\n",
        "\n",
        "    # fill pi[s] for each state s\n",
        "    for s in range(nS):\n",
        "        action_values = []\n",
        "        for a in range(nA):\n",
        "            expected_return = 0.0\n",
        "            for (prob, next_state, reward, terminated) in P[s][a]:\n",
        "                expected_return += prob * (reward + gamma * V[next_state])\n",
        "            action_values.append(expected_return)\n",
        "        pi[s] = np.argmax(action_values)\n",
        "\n",
        "    return pi\n",
        "\n",
        "pi_vi = greedy_policy_from_V(P, V_star, nS, nA, gamma=gamma)\n",
        "pi_vi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzDIqKUW1UB-"
      },
      "source": [
        "This function:\n",
        "\n",
        "Executes a fixed policy π in the environment\n",
        "\n",
        "Runs multiple episodes\n",
        "\n",
        "Returns the average reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjSEXukqybkQ",
        "outputId": "98710955-5a12-42ee-f635-cb9bc5d84091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value Iteration policy performance:\n",
            "  mean return = 1.0 std = 0.0\n"
          ]
        }
      ],
      "source": [
        "def evaluate_policy(env, pi, episodes=200, max_steps=200):\n",
        "    returns = []\n",
        "    for _ in range(episodes):\n",
        "        s, _ = env.reset(seed=None)\n",
        "        total = 0.0\n",
        "        for _ in range(max_steps):\n",
        "            a = int(pi[s])\n",
        "            s, r, terminated, truncated, _ = env.step(a)\n",
        "            total += r\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "        returns.append(total)\n",
        "    return float(np.mean(returns)), float(np.std(returns))\n",
        "\n",
        "mean_vi, std_vi = evaluate_policy(env, pi_vi, episodes=200)\n",
        "print(\"Value Iteration policy performance:\")\n",
        "print(\"  mean return =\", mean_vi, \"std =\", std_vi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK6VYe7AyjWy"
      },
      "source": [
        "### Checkpoint\n",
        "\n",
        "> 1. Value Iteration never \"plays the game\" to learn. So how does it improve?\n",
        "\n",
        "**Answer:** Value Iteration improves by performing \"sweeps\" through the state space, applying Bellman backups at each state. It uses the transition model P(s'|s,a) to compute expected values without actually experiencing transitions. Each backup propagates value information backwards through the state space based on the known dynamics. This is called \"planning\" - reasoning about optimal behavior using a model of the environment rather than learning from direct experience.\n",
        "\n",
        "> 2. What assumption does Value Iteration require that Q-learning does not?\n",
        "\n",
        "**Answer:** Value Iteration requires knowledge of the transition dynamics P(s'|s,a) and reward function R(s,a,s'). This makes it a **model-based** method. Q-learning, on the other hand, is **model-free** - it learns optimal action-values directly from sampled experience (s, a, r, s') without needing to know the underlying transition probabilities. This makes Q-learning more applicable to real-world problems where we can interact with an environment but don't have access to its internal model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGzk_dQsyxZi"
      },
      "source": [
        "### Q-learning (Learning / Model-Free Control)\n",
        "\n",
        "Q-learning learns an action-value table Q(s,a) using sampled experience\n",
        "\n",
        "The update is:\n",
        "\n",
        "Q(s,a) ← Q(s,a) + α [ r + γ maxₐ′ Q(s′,a′) − Q(s,a) ]\n",
        "\n",
        "This is a sampled Bellman optimality backup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c-0nFJQ1iXv"
      },
      "source": [
        "---\n",
        "\n",
        "Q-learning maintains a table Q(s,a) and updates it via:\n",
        "\n",
        "Q(s,a) ← Q(s,a) + α [ r + γ maxₐ′ Q(s′,a′) − Q(s,a) ]\n",
        "\n",
        "\n",
        "This is a sampled Bellman optimality backup:\n",
        "\n",
        "No transition model needed\n",
        "\n",
        "Uses experience tuples (s, a, r, s′)\n",
        "\n",
        "---\n",
        "\n",
        "`epsilon_greedy_action`\n",
        "\n",
        "This function implements ε-greedy exploration:\n",
        "\n",
        "With probability ε: explore (random action)\n",
        "\n",
        "With probability 1−ε: exploit (best known action)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KfCcFEyiyfSl"
      },
      "outputs": [],
      "source": [
        "Q = np.zeros((nS, nA), dtype=np.float64)\n",
        "\n",
        "def greedy_action(Q, s):\n",
        "    \"\"\"Return argmax_a Q(s,a).\"\"\"\n",
        "    return int(np.argmax(Q[s]))\n",
        "\n",
        "def epsilon_greedy_action(env, Q, s, epsilon):\n",
        "    \"\"\"\n",
        "    With probability epsilon: random action\n",
        "    Otherwise: greedy action\n",
        "\n",
        "    TODO: implement.\n",
        "    \"\"\"\n",
        "    # if random.uniform(0,1) < epsilon: return env.action_space.sample()\n",
        "    # else return greedy_action(Q,s)\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "        return env.action_space.sample()\n",
        "    else:\n",
        "        return greedy_action(Q, s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ozVrUbb3y-RN"
      },
      "outputs": [],
      "source": [
        "def epsilon_schedule(episode, eps_start=1.0, eps_min=0.05, decay_rate=0.0005):\n",
        "    \"\"\"\n",
        "    Exponential decay:\n",
        "      eps = max(eps_min, eps_start * exp(-decay_rate * episode))\n",
        "    TODO: implement.\n",
        "    \"\"\"\n",
        "    eps = max(eps_min, eps_start * np.exp(-decay_rate * episode))\n",
        "    return eps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnF3jHHS13DC"
      },
      "source": [
        "This is the full agent–environment loop:\n",
        "\n",
        "Reset environment\n",
        "\n",
        "Choose action via ε-greedy\n",
        "\n",
        "Observe (s′, r)\n",
        "\n",
        "Apply Q-learning update\n",
        "\n",
        "Repeat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238,
          "referenced_widgets": [
            "8a1af80dcc404ac08b329cbb5ac8b7b0",
            "963cce2befc549db86d31068d085bec6",
            "74347396607048c2851ac9f85c12d08e",
            "e0094b1632d84b7c9f5b94a4f37da0a4",
            "4a184edc237a45328bd031dc7d7a5193",
            "75482bf831bc41b49137e040877d4490",
            "71d8f2702438475c84d8d08d0776dad9",
            "b75acc6cb6824b918bb7400af7d0a1e6",
            "dc49d5de60f34ad68483e10d67e34374",
            "a49a84735e9545b6b751d2cbbfe62404",
            "8d4d7817b77c481eb98df43f8db1cb90"
          ]
        },
        "id": "byrc93M-zA5e",
        "outputId": "3399a347-1dcb-44fd-a58a-07c34c99fbda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 20075.81it/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "0",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "2",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "3",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "5dcf5023-0de2-4633-bc36-10f4ff5ba8f7",
              "rows": [
                [
                  "0",
                  "0.7350918906249998",
                  "0.7737809374999999",
                  "0.7737809374999999",
                  "0.7350918906249998"
                ],
                [
                  "1",
                  "0.7350918906249998",
                  "0.0",
                  "0.8145062499999999",
                  "0.7737809374999999"
                ],
                [
                  "2",
                  "0.7737809374999999",
                  "0.8573749999999999",
                  "0.7737809374999999",
                  "0.8145062499999999"
                ],
                [
                  "3",
                  "0.8145062499999999",
                  "0.0",
                  "0.7737809343715599",
                  "0.7737809374999999"
                ],
                [
                  "4",
                  "0.7737809374999999",
                  "0.8145062499999999",
                  "0.0",
                  "0.7350918906249998"
                ]
              ],
              "shape": {
                "columns": 4,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.735092</td>\n",
              "      <td>0.773781</td>\n",
              "      <td>0.773781</td>\n",
              "      <td>0.735092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.735092</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.814506</td>\n",
              "      <td>0.773781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.773781</td>\n",
              "      <td>0.857375</td>\n",
              "      <td>0.773781</td>\n",
              "      <td>0.814506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.814506</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.773781</td>\n",
              "      <td>0.773781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.773781</td>\n",
              "      <td>0.814506</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.735092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3\n",
              "0  0.735092  0.773781  0.773781  0.735092\n",
              "1  0.735092  0.000000  0.814506  0.773781\n",
              "2  0.773781  0.857375  0.773781  0.814506\n",
              "3  0.814506  0.000000  0.773781  0.773781\n",
              "4  0.773781  0.814506  0.000000  0.735092"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def q_learning_train(env, Q, episodes=10_000, max_steps=100,\n",
        "                     alpha=0.7, gamma=0.95,\n",
        "                     eps_start=1.0, eps_min=0.05, decay_rate=0.0005):\n",
        "    \"\"\"\n",
        "    Train Q using Q-learning with epsilon-greedy exploration.\n",
        "\n",
        "    TODO:\n",
        "      - pick action using epsilon_greedy_action\n",
        "      - apply Q-learning update\n",
        "    \"\"\"\n",
        "    for ep in tqdm(range(episodes)):\n",
        "        epsilon = epsilon_schedule(ep, eps_start, eps_min, decay_rate)\n",
        "        s, _ = env.reset(seed=None)\n",
        "\n",
        "        for t in range(max_steps):\n",
        "            a = epsilon_greedy_action(env, Q, s, epsilon)\n",
        "            s2, r, terminated, truncated, _ = env.step(a)\n",
        "\n",
        "            # Q-learning update\n",
        "            # target = r + gamma * max_a' Q[s2, a']   (if not terminal; optional nuance)\n",
        "            # Q[s,a] <- Q[s,a] + alpha*(target - Q[s,a])\n",
        "            # Hint: np.max(Q[s2]) gives max over actions\n",
        "            if terminated or truncated:\n",
        "                target = r\n",
        "            else:\n",
        "                target = r + gamma * np.max(Q[s2])\n",
        "            Q[s, a] = Q[s, a] + alpha * (target - Q[s, a])\n",
        "\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "            s = s2\n",
        "\n",
        "    return Q\n",
        "\n",
        "Q = np.zeros((nS, nA), dtype=np.float64)\n",
        "Q = q_learning_train(env, Q)\n",
        "pd.DataFrame(Q).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjl9bGK4zI0n",
        "outputId": "d86af529-40fa-41d8-9320-5bbc9558bfcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q-learning policy performance:\n",
            "  mean return = 1.0 std = 0.0\n"
          ]
        }
      ],
      "source": [
        "pi_q = np.array([greedy_action(Q, s) for s in range(nS)], dtype=np.int64)\n",
        "mean_q, std_q = evaluate_policy(env, pi_q, episodes=200)\n",
        "print(\"Q-learning policy performance:\")\n",
        "print(\"  mean return =\", mean_q, \"std =\", std_q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji3pUERxzN67"
      },
      "source": [
        "### Checkpoint\n",
        "\n",
        "\n",
        "> 1. Why do we need ε-greedy at all?\n",
        "\n",
        "**Answer:** ε-greedy is needed for **exploration**. Without exploration, the agent might never discover the optimal path because it would only exploit what it already knows. If Q-values are initialized poorly or the agent gets unlucky early on, it could get stuck taking suboptimal actions forever. ε-greedy ensures that with probability ε, the agent takes random actions to explore new state-action pairs and discover potentially better strategies. This balances exploration (discovering new information) with exploitation (using current knowledge).\n",
        "\n",
        "> 2. What do you think happens if ε is fixed at 0.0 from the start?\n",
        "\n",
        "**Answer:** If ε = 0.0 from the start, the agent would be **purely greedy** and never explore. With Q-values initialized to zeros, all actions would look equally good initially, so the agent would consistently pick the same action (e.g., action 0 via argmax). This means it would likely never discover the goal state or learn the optimal policy. The agent would be stuck exploiting its initial (poor) Q-estimates without ever exploring to find better paths. In stochastic environments, this is even worse because the agent might learn a very biased policy based on limited experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylo_aDA8zK0w",
        "outputId": "70e040ae-3edb-4df0-b275-fd2f0544eb76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison (deterministic FrozenLake, is_slippery=False)\n",
            "  Value Iteration: mean=1.000, std=0.000\n",
            "  Q-learning:      mean=1.000, std=0.000\n"
          ]
        }
      ],
      "source": [
        "print(\"Comparison (deterministic FrozenLake, is_slippery=False)\")\n",
        "print(f\"  Value Iteration: mean={mean_vi:.3f}, std={std_vi:.3f}\")\n",
        "print(f\"  Q-learning:      mean={mean_q:.3f}, std={std_q:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84siEtK02IEU"
      },
      "source": [
        "This cell reshapes the optimal value function V*(s) from a 1-D table into the original 4×4 grid layout of FrozenLake, and displays it as a heatmap.\n",
        "\n",
        "Each cell in the grid corresponds to:\n",
        "\n",
        "A state in the environment\n",
        "\n",
        "The estimated expected discounted return starting from that state, assuming optimal behavior\n",
        "\n",
        "Darker (or brighter) colors indicate states with higher expected return."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "KoYVxw_Xzj1G",
        "outputId": "b415aaac-12f4-45a9-ed80-cb9bda4204c5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "V_grid = V_star.reshape(4,4)\n",
        "plt.figure()\n",
        "plt.title(\"V* from Value Iteration (reshaped to 4x4)\")\n",
        "plt.imshow(V_grid)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11_6dpGizqgJ"
      },
      "source": [
        "### Turn on Stochasticity\n",
        "\n",
        "Now `flip is_slippery=True`\n",
        "\n",
        "This introduces stochastic transitions. Your MDP model still exists, but learning becomes noisier and evaluation has variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1l5rquBRznpA"
      },
      "outputs": [],
      "source": [
        "env_slip = gym.make(\"FrozenLake-v1\", map_name=\"4x4\", is_slippery=True, render_mode=\"rgb_array\")\n",
        "_ = env_slip.reset(seed=SEED)\n",
        "env_slip.action_space.seed(SEED)\n",
        "env_slip.observation_space.seed(SEED)\n",
        "\n",
        "P_slip = env_slip.unwrapped.P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "4cec96039449432d8fa08b64dccdccac",
            "3f2d0b98d3ca4b339075bf129ce5948c",
            "cfda5bd2445a46d297911d3458b74f8e",
            "97de56b6b48540268a15620e829c5bd8",
            "e9b8fff0eb1a44e4b445d79d2c810b80",
            "d997f0aa9a964b109a03efa3d67e8da0",
            "e5e2e911b8e146d3a21f2a4c82484fb1",
            "a0c745cc9bf4460fb3581ad5b152fc7f",
            "39c842b382ad46f6a1a3520e45cfb092",
            "7342d050e25942f690214fefc2c7a696",
            "4adbedc2bc50417ea257c2fddce93096"
          ]
        },
        "id": "7KHR1SHhzzdy",
        "outputId": "766165f7-d844-4701-81e5-c7c7447d3b66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value Iteration converged in 138 iterations (delta=9.72e-09).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20000/20000 [00:03<00:00, 5402.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison (stochastic FrozenLake, is_slippery=True)\n",
            "  Value Iteration: mean=0.704, std=0.456\n",
            "  Q-learning:      mean=0.610, std=0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Value Iteration policy on slippery dynamics\n",
        "V_star_slip = value_iteration(P_slip, nS, nA, gamma=gamma)\n",
        "pi_vi_slip = greedy_policy_from_V(P_slip, V_star_slip, nS, nA, gamma=gamma)\n",
        "mean_vi_s, std_vi_s = evaluate_policy(env_slip, pi_vi_slip, episodes=500)\n",
        "\n",
        "# Q-learning on slippery dynamics\n",
        "Q_slip = np.zeros((nS, nA), dtype=np.float64)\n",
        "Q_slip = q_learning_train(env_slip, Q_slip, episodes=20_000)  # more episodes helps\n",
        "pi_q_slip = np.array([greedy_action(Q_slip, s) for s in range(nS)], dtype=np.int64)\n",
        "mean_q_s, std_q_s = evaluate_policy(env_slip, pi_q_slip, episodes=500)\n",
        "\n",
        "print(\"Comparison (stochastic FrozenLake, is_slippery=True)\")\n",
        "print(f\"  Value Iteration: mean={mean_vi_s:.3f}, std={std_vi_s:.3f}\")\n",
        "print(f\"  Q-learning:      mean={mean_q_s:.3f}, std={std_q_s:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "39c842b382ad46f6a1a3520e45cfb092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f2d0b98d3ca4b339075bf129ce5948c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d997f0aa9a964b109a03efa3d67e8da0",
            "placeholder": "​",
            "style": "IPY_MODEL_e5e2e911b8e146d3a21f2a4c82484fb1",
            "value": "100%"
          }
        },
        "4a184edc237a45328bd031dc7d7a5193": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4adbedc2bc50417ea257c2fddce93096": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cec96039449432d8fa08b64dccdccac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f2d0b98d3ca4b339075bf129ce5948c",
              "IPY_MODEL_cfda5bd2445a46d297911d3458b74f8e",
              "IPY_MODEL_97de56b6b48540268a15620e829c5bd8"
            ],
            "layout": "IPY_MODEL_e9b8fff0eb1a44e4b445d79d2c810b80"
          }
        },
        "71d8f2702438475c84d8d08d0776dad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7342d050e25942f690214fefc2c7a696": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74347396607048c2851ac9f85c12d08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b75acc6cb6824b918bb7400af7d0a1e6",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc49d5de60f34ad68483e10d67e34374",
            "value": 10000
          }
        },
        "75482bf831bc41b49137e040877d4490": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a1af80dcc404ac08b329cbb5ac8b7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_963cce2befc549db86d31068d085bec6",
              "IPY_MODEL_74347396607048c2851ac9f85c12d08e",
              "IPY_MODEL_e0094b1632d84b7c9f5b94a4f37da0a4"
            ],
            "layout": "IPY_MODEL_4a184edc237a45328bd031dc7d7a5193"
          }
        },
        "8d4d7817b77c481eb98df43f8db1cb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "963cce2befc549db86d31068d085bec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75482bf831bc41b49137e040877d4490",
            "placeholder": "​",
            "style": "IPY_MODEL_71d8f2702438475c84d8d08d0776dad9",
            "value": "100%"
          }
        },
        "97de56b6b48540268a15620e829c5bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7342d050e25942f690214fefc2c7a696",
            "placeholder": "​",
            "style": "IPY_MODEL_4adbedc2bc50417ea257c2fddce93096",
            "value": " 20000/20000 [00:06&lt;00:00, 2632.33it/s]"
          }
        },
        "a0c745cc9bf4460fb3581ad5b152fc7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a49a84735e9545b6b751d2cbbfe62404": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b75acc6cb6824b918bb7400af7d0a1e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfda5bd2445a46d297911d3458b74f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0c745cc9bf4460fb3581ad5b152fc7f",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39c842b382ad46f6a1a3520e45cfb092",
            "value": 20000
          }
        },
        "d997f0aa9a964b109a03efa3d67e8da0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc49d5de60f34ad68483e10d67e34374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0094b1632d84b7c9f5b94a4f37da0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a49a84735e9545b6b751d2cbbfe62404",
            "placeholder": "​",
            "style": "IPY_MODEL_8d4d7817b77c481eb98df43f8db1cb90",
            "value": " 10000/10000 [00:19&lt;00:00, 511.97it/s]"
          }
        },
        "e5e2e911b8e146d3a21f2a4c82484fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9b8fff0eb1a44e4b445d79d2c810b80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
